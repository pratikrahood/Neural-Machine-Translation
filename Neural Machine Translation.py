# -*- coding: utf-8 -*-
"""22210643_Rahood.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C_K_SCIumW1J8ug7xTThmYx_rYFqQv9K

# Overview
**Assignment ** focuses on the training on a Neural Machine Translation (NMT) system for English-Irish translation where English is the source language and Irish is the target language.



## Task 1 - Data Collection and Preprocessing
## Task 1a. Data Loading
Dataset: https://www.dropbox.com/s/zkgclwc9hrx7y93/DGT-en-ga.txt.zip?dl=0
*  Download a English-Irish dataset and decompress it. The `DGT.en-ga.en` file contains a list english sentences and `DGT.en-ga.ga` contains the paralell Irish sentences. Read both files into the Jupyter environment and load them into a pandas dataframe.
* Randomly sample 12,000 rows.
* Split the sampled data into train (10k), development (1k) and test set (1k)
"""

from google.colab import drive
drive.mount('/content/drive')

# Your Code Here
import pandas as pd
import random
from sklearn.model_selection import train_test_split

# load english sentences
with open('/content/drive/MyDrive/ANLP Assignment 2/DGT.en-ga.en', 'r', encoding='utf-8') as f:
    eng_sentences = f.readlines()

# load irish sentences
with open('/content/drive/MyDrive/ANLP Assignment 2/DGT.en-ga.ga', 'r', encoding='utf-8') as f:
    irish_sentences = f.readlines()

# combine english and irish sentences into a dataframe
df = pd.DataFrame({'sourceString': eng_sentences, 'targetString': irish_sentences})

# randomly sample 12,000 rows
df = df.sample(n=12000, random_state=42)

# split the sampled data into train (10k), development (1k) and test set (1k)
train_val, test = train_test_split(df, test_size=0.0833, random_state=42) # split 1k for test
train, val = train_test_split(train_val, test_size=0.0909, random_state=42) # split 1k for dev


dataset = pd.concat([train, val, test])

train.shape,val.shape,test.shape

"""## Task 1b. Preprocessing
* Add '<bof>' to denote beginning of sentence and '<eos\>' to denote the end of the sentence to each target line.
* Perform the following pre-processing steps:
  * Lowercase the text
  * Remove all punctuation
  * tokenize the text
*  Build seperate vocabularies for each language.
  * Assign each unique word an id value
*Print statistics on the selected dataset:
  * Number of samples
  * Number of unique source language tokens
  * Number of unique target language tokens
  * Max sequence length of source language
  * Max sequence length of target language


"""

# Refrence- Advanced NLP Lab 08 provided on blackboard

from nltk.tokenize import word_tokenize
from typing import List
import re

class Langauge:
  def __init__(self, language: str):
    self.language = language
    self.word2index = {"bof": 0, "eos": 1}
    self.index2word = {0: "bof", 1: "eos"}
    self.word2count = {}
    self.n_words = len(self.index2word)

  def addSentence(self, sentence: str):

    text = sentence.lower()
    clean_text = re.sub(r'[^\w\s]', '', text).strip()
    for word in word_tokenize(clean_text):
      self.addWord(word)

  def addWord(self, word: str):

    if word not in self.word2index:
      self.word2index[word] = self.n_words
      self.word2count[word] = 1
      self.index2word[self.n_words] = word
      self.n_words += 1
    else:
      self.word2count[word] += 1

  def encodeSentence(self, sentence: str) -> List[int]:

    text = sentence.lower()
    clean_text = re.sub(r'[^\w\s]', '',text).strip()
    clean_text = "bof " + clean_text + " eos"
    return [self.word2index[word] for word in word_tokenize(clean_text) if word in self.word2index]

  def decodeIds(self, ids: list) -> List[str]:

    return " ".join([self.index2word[tok] for tok in ids])

# Refrence- Advanced NLP Lab 08 provided on blackboard

import nltk
nltk.download('punkt')
from tqdm.notebook import tqdm

english = Langauge("english")
irish = Langauge("irish")

for _, row in tqdm(dataset.iterrows(), total=len(dataset)):
  english.addSentence(row["sourceString"])
  irish.addSentence(row["targetString"])
print(f"Size of English vocab: {irish.n_words}")
print(f"Size of irish vocab: {english.n_words}")

# Refrence- Advanced NLP Lab 08 provided on blackboard

import torch
from tensorflow.keras.utils import pad_sequences
import pandas as pd

def encode_features(
    df: pd.DataFrame,
    english: Langauge,
    irish: Langauge,
    pad_token: int = 0,
    max_seq_length = 10
  ):

  source = []
  target = []

  for _, row in df.iterrows():
    source.append(english.encodeSentence(row["sourceString"]))
    target.append(irish.encodeSentence(row["targetString"]))

  source = pad_sequences(
      source,
      maxlen=max_seq_length,
      padding="post",
      truncating = "post",
      value=pad_token
    )

  target = pad_sequences(
      target,
      maxlen=max_seq_length,
      padding="post",
      truncating = "post",
      value=pad_token
    )

  return source, target

train_source, train_target = encode_features(train, english, irish)
val_source, val_target = encode_features(val, english, irish)
test_source, test_target = encode_features(test, english, irish)

print(f"Shapes of train source {train_source.shape}, and target {train_target.shape}")

# Refrence- Advanced NLP Lab 08 provided on blackboard
from torch.utils.data import DataLoader, TensorDataset

train_dl = DataLoader(
    TensorDataset(
        torch.LongTensor(train_source),
        torch.LongTensor(train_target)
    ),
    shuffle = True,
    batch_size = 32
)

val_dl = DataLoader(
    TensorDataset(
        torch.LongTensor(val_source),
        torch.LongTensor(val_target)
    ),
    shuffle = False,
    batch_size = 32
)

test_dl = DataLoader(
    TensorDataset(
        torch.LongTensor(test_source),
        torch.LongTensor(test_target)
    ),
    shuffle = False,
    batch_size = 32
)

"""## Task 2. Model Implementation and Training



## Task 2a. Encoder-Decoder Model Implementation
Implement an Encoder-Decoder model in Pytorch with the following components
* A single layer RNN based encoder.
* A single layer RNN based decoder
* A Encoder-Decoder model based on the above components that support sequence-to-sequence modelling. For the encoder/decoder you can use RNN, LSTMs or GRU. Use a hidden dimension of 256 or less depending on your compute constraints.
"""

#Refrence- https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb

import torch
import torch.nn as nn
import torch.nn.functional as F


class Encoder(nn.Module):
    def __init__(self, input_dim, emb_dimension, hidden_dimension, n_layers, dropout):
        super().__init__()

        self.hidden_dimension = hidden_dimension
        self.n_layers = n_layers

        self.embedding = nn.Embedding(input_dim, emb_dimension)

        self.r_n_n = nn.LSTM(emb_dimension, hidden_dimension, n_layers, dropout = dropout)

        self.dropout = nn.Dropout(dropout)

    def forward(self, src):

        embedded = self.dropout(self.embedding(src))
        outputs, (hidden, x) = self.r_n_n(embedded)
        return hidden, x

class Decoder(nn.Module):
    def __init__(self, output_dimension, emb_dimension, hidden_dimension, n_layers, dropout):
        super().__init__()

        self.output_dimension = output_dimension
        self.hidden_dimension = hidden_dimension
        self.n_layers = n_layers

        self.embedding = nn.Embedding(output_dimension, emb_dimension)

        self.r_n_n = nn.LSTM(emb_dimension, hidden_dimension, n_layers, dropout = dropout)

        self.fc_out = nn.Linear(hidden_dimension, output_dimension)

        self.dropout = nn.Dropout(dropout)

    def forward(self, input, hidden, x):

        input = input.unsqueeze(0)

        embedded = self.dropout(self.embedding(input))

        output, (hidden, x) = self.r_n_n(embedded, (hidden, x))

        prediction = self.fc_out(output.squeeze(0))

        return prediction, hidden, x

#Refrence- https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb
class Seq2Seq(nn.Module):
    def __init__(self, encoder, decoder, device):
        super().__init__()

        self.encoder = encoder
        self.decoder = decoder
        self.device = device

        assert encoder.hidden_dimension == decoder.hidden_dimension, \
            "Hidden dimensions of encoder and decoder must be equal!"
        assert encoder.n_layers == decoder.n_layers, \
            "Encoder and decoder must have equal number of layers!"

    def forward(self, src, trg, teacher_forcing_ratio = 0.5):

        batch_size = trg.shape[1]
        trg_len = trg.shape[0]
        trg_vocab_size = self.decoder.output_dimension

        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)

        hidden, x = self.encoder(src)

        input = trg[0,:]

        for t in range(1, trg_len):

            output, hidden, x = self.decoder(input, hidden, x)

            outputs[t] = output

            teacher_force = random.random() < teacher_forcing_ratio

            top1 = output.argmax(1)

            input = trg[t] if teacher_force else top1

        return outputs

# Refrence- Advanced NLP Lab 08 provided on blackboard
#Refrence- https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb

INPUT_DIM = english.n_words
OUTPUT_DIMENSION = irish.n_words
ENC_EMB_DIMENSION = 256
DEC_EMB_DIMENSION = 256
HID_DIMENSION = 512
N_LAYERS = 2
ENC_DROPOUT = 0.5
DEC_DROPOUT = 0.5

enc = Encoder(INPUT_DIM, ENC_EMB_DIMENSION, HID_DIMENSION, N_LAYERS, ENC_DROPOUT)
dec = Decoder(OUTPUT_DIMENSION, DEC_EMB_DIMENSION, HID_DIMENSION, N_LAYERS, DEC_DROPOUT)


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

basic_model = Seq2Seq(enc, dec, device).to(device)

def init_weights(m):
    for name, param in m.named_parameters():
        if 'weight' in name:
            nn.init.normal_(param.data, mean=0, std=0.01)
        else:
            nn.init.constant_(param.data, 0)

basic_model.apply(init_weights)

"""## Task 2b. Training
Implement the code to train the Encoder-Decoder model on the Irish-English data. You will write code for the following:
* Training, validation and test dataloaders
* A training loop which trains the model for 5 epoch. Evaluate the loop at the end of each Epoch. Print out the train perplexity and validation perplexity after each epoch.
"""

# Refrence- Advanced NLP Lab 08 provided on blackboard
#Refrence- https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb

from tqdm.notebook import tqdm
import numpy as np
optimizer = torch.optim.Adam(basic_model.parameters())

device = "cuda:0" if torch.cuda.is_available() else "cpu"

basic_model.to(device)

EPOCHS = 5
best_val_loss = float('inf')

for epoch in range(EPOCHS):

  basic_model.train()
  epoch_loss = 0
  for batch in tqdm(train_dl, total=len(train_dl)):

     src = batch[0].transpose(1, 0).to(device)
     trg = batch[1].transpose(1, 0).to(device)

     optimizer.zero_grad()

     output = basic_model(src, trg)

     output_dimension = output.shape[-1]
     output = output[1:].view(-1, output_dimension).to(device)
     trg = trg[1:].reshape(-1)

     loss = F.cross_entropy(output, trg)
     loss.backward()

     torch.nn.utils.clip_grad_norm_(basic_model.parameters(), 1)
     optimizer.step()
     epoch_loss += loss.item()

  train_loss = round(epoch_loss / len(train_dl), 3)

  eval_loss = 0
  basic_model.eval()
  for batch in tqdm(val_dl, total=len(val_dl)):
    src = batch[0].transpose(1, 0).to(device)
    trg = batch[1].transpose(1, 0).to(device)

    with torch.no_grad():
      output = basic_model(src, trg)

      output_dimension = output.shape[-1]
      output = output[1:].view(-1, output_dimension).to(device)
      trg = trg[1:].reshape(-1)

      loss = F.cross_entropy(output, trg)

      eval_loss += loss.item()

  val_loss = round(eval_loss / len(val_dl), 3)
  print(f"Epoch {epoch} | train loss {train_loss} | train ppl {np.exp(train_loss)} | val ppl {np.exp(val_loss)}")


  if val_loss < best_val_loss:
    best_val_loss = val_loss
    torch.save(basic_model.state_dict(), 'best-model.pt')

"""# Task 2c. Evaluation on the Test Set
Use the trained model to translate the text from the source language into the target language on the test set. Evaluate the performance of the model on the test set using the BLEU metric and print out the average the BLEU score.
"""

# Your code here
# Refrence- Advanced NLP Lab 08 provided on blackboard
def translate_sentence(
    text: str,
    basic_model: Seq2Seq,
    english: Langauge,
    irish: Langauge,
    device: str,
    max_len: int = 10,
  ) -> str:

  input_ids = english.encodeSentence(text)
  input_tensor = torch.LongTensor(input_ids).unsqueeze(1).to(device)

  with torch.no_grad():
    encoder_outputs, hidden= basic_model.encoder(input_tensor)

  trg_indexes = [irish.word2index["bof"]]

  for i in range(max_len):
    trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)

    with torch.no_grad():
      output, hidden,x = basic_model.decoder(trg_tensor, hidden, encoder_outputs)

    pred_token = torch.argmax(output).item()
    trg_indexes.append(pred_token)

    if pred_token == irish.word2index["eos"]:
      break

  return "".join(irish.decodeIds(trg_indexes))

# Refrence- Advanced NLP Lab 07 provided on blackboard
def blue_score(reference_sentence, condidate_sentence):
  return len([word for word in condidate_sentence if word in reference_sentence])/len(reference_sentence)

bleu_score = []
for index,rows in test.iterrows():
  target=translate_sentence(rows['sourceString'], basic_model, english, irish, device)
  bleu_score.append(blue_score((rows['targetString']),target))

np.mean(bleu_score)

"""## Task 3. Improving NMT using Attention
Extend the Encoder-Decoder model from Task 2 with the attention mechanism. Retrain the model and evaluate on test set. Print the updated average BLEU score on the test set. In a few sentences explains which model is the best for translation.
"""

# Refrence- Advanced NLP Lab 08 provided on blackboard
import torch
import torch.nn as nn
import torch.nn.functional as F

class EncoderGRU(nn.Module):
    def __init__(
        self,
        input_vocab_size,
        hidden_dim,
        encoder_hidden_dimension,
        decoder_hidden_dimension,
        dropout_prob = .5
      ):

        super().__init__()
        self.embedding = nn.Embedding(input_vocab_size, hidden_dim)
        self.rnn = nn.GRU(hidden_dim, encoder_hidden_dimension, bidirectional = True)
        self.fc = nn.Linear(encoder_hidden_dimension * 2, decoder_hidden_dimension)
        self.dropout = nn.Dropout(dropout_prob)

    def forward(self, src):

        embedded = self.dropout(self.embedding(src))

        outputs, hidden = self.rnn(embedded)

        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))
        return outputs, hidden


class Attention(nn.Module):
    def __init__(
        self,
        enc_hidden_dimension,
        dec_hidden_dimension
      ):
        super().__init__()

        self.attn = nn.Linear((enc_hidden_dimension * 2) + dec_hidden_dimension, dec_hidden_dimension)
        self.v = nn.Linear(dec_hidden_dimension, 1, bias = False)

    def forward(self, hidden, encoder_outputs):

        batch_size = encoder_outputs.shape[1]
        src_len = encoder_outputs.shape[0]

        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)

        encoder_outputs = encoder_outputs.permute(1, 0, 2)

        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2)))

        attention = self.v(energy).squeeze(2)

        return F.softmax(attention, dim=1)


class DecoderGRU(nn.Module):
    def __init__(
        self,
        target_vocab_size,
        hidden_dim,
        enc_hidden_dimension,
        dec_hidden_dimension,
        dropout
      ):
        super().__init__()

        self.output_dimension = target_vocab_size
        self.attention = Attention(enc_hidden_dimension, dec_hidden_dimension)

        self.embedding = nn.Embedding(target_vocab_size, hidden_dim)

        self.rnn = nn.GRU((enc_hidden_dimension * 2) + hidden_dim, dec_hidden_dimension)

        self.fc_out = nn.Linear(
            (enc_hidden_dimension * 2) + dec_hidden_dimension + hidden_dim,
            target_vocab_size
          )
        self.dropout = nn.Dropout(dropout)

    def forward(self, input, hidden, encoder_outputs):

        input = input.unsqueeze(0)

        embedded = self.dropout(self.embedding(input))

        a = self.attention(hidden, encoder_outputs)
        a = a.unsqueeze(1)

        encoder_outputs = encoder_outputs.permute(1, 0, 2)

        weighted = torch.bmm(a, encoder_outputs)
        weighted = weighted.permute(1, 0, 2)

        rnn_input = torch.cat((embedded, weighted), dim = 2)

        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))

        embedded = embedded.squeeze(0)
        output = output.squeeze(0)
        weighted = weighted.squeeze(0)

        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))
        return prediction, hidden.squeeze(0)

# Refrence- Advanced NLP Lab 08 provided on blackboard
import random
class EncoderDecoder(nn.Module):
    def __init__(self, encoder, decoder):
        super().__init__()

        self.encoder = encoder
        self.decoder = decoder

    def forward(self, src, trg, teacher_forcing_ratio = 0.5):

        batch_size = src.shape[1]
        trg_len = trg.shape[0]
        trg_vocab_size = self.decoder.output_dimension

        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size)

        encoder_outputs, hidden = self.encoder(src)

        input = trg[0,:]

        for t in range(1, trg_len):

            output, hidden = self.decoder(input, hidden, encoder_outputs)

            outputs[t] = output

            teacher_force = random.random() < teacher_forcing_ratio

            top1 = output.argmax(1)

            input = trg[t] if teacher_force else top1
        return outputs

# Refrence- Advanced NLP Lab 08 provided on blackboard
INPUT_DIM = english.n_words
OUTPUT_DIMENSION = irish.n_words
ENC_EMB_DIMENSION = 256
DEC_EMB_DIMENSION = 256
ENC_HID_DIMENSION = 128
DEC_HID_DIMENSION = 128
ENC_DROPOUT = 0.5
DEC_DROPOUT = 0.5

enc = EncoderGRU(INPUT_DIM, ENC_EMB_DIMENSION, ENC_HID_DIMENSION, DEC_HID_DIMENSION, ENC_DROPOUT)
dec = DecoderGRU(OUTPUT_DIMENSION, DEC_EMB_DIMENSION, ENC_HID_DIMENSION, DEC_HID_DIMENSION, DEC_DROPOUT)

model1 = EncoderDecoder(enc, dec)

def init_weights(m):
    for name, param in m.named_parameters():
        if 'weight' in name:
            nn.init.normal_(param.data, mean=0, std=0.01)
        else:
            nn.init.constant_(param.data, 0)

model1.apply(init_weights)

# Refrence- Advanced NLP Lab 08 provided on blackboard
from tqdm.notebook import tqdm
import numpy as np
optimizer = torch.optim.Adam(model1.parameters())

device = "cuda:0" if torch.cuda.is_available() else "cpu"

model1.to(device)

EPOCHS = 5
best_val_loss = float('inf')

for epoch in range(EPOCHS):

  model1.train()
  epoch_loss = 0
  for batch in tqdm(train_dl, total=len(train_dl)):

     src = batch[0].transpose(1, 0).to(device)
     trg = batch[1].transpose(1, 0).to(device)

     optimizer.zero_grad()

     output = model1(src, trg)

     output_dimension = output.shape[-1]
     output = output[1:].view(-1, output_dimension).to(device)
     trg = trg[1:].reshape(-1)

     loss = F.cross_entropy(output, trg)
     loss.backward()

     torch.nn.utils.clip_grad_norm_(model1.parameters(), 1)
     optimizer.step()
     epoch_loss += loss.item()

  train_loss = round(epoch_loss / len(train_dl), 3)

  eval_loss = 0
  model1.eval()
  for batch in tqdm(val_dl, total=len(val_dl)):
    src = batch[0].transpose(1, 0).to(device)
    trg = batch[1].transpose(1, 0).to(device)

    with torch.no_grad():
      output = model1(src, trg)

      output_dimension = output.shape[-1]
      output = output[1:].view(-1, output_dimension).to(device)
      trg = trg[1:].reshape(-1)

      loss = F.cross_entropy(output, trg)

      eval_loss += loss.item()

  val_loss = round(eval_loss / len(val_dl), 3)
  print(f"Epoch {epoch} | train loss {train_loss} | train ppl {np.exp(train_loss)} | val ppl {np.exp(val_loss)}")


  if val_loss < best_val_loss:
    best_val_loss = val_loss
    torch.save(model1.state_dict(), 'best-model1.pt')

# Refrence- Advanced NLP Lab 08 provided on blackboard

def translate_sentence1(
    text: str,
    model1: EncoderDecoder,
    english: Langauge,
    irish: Langauge,
    device: str,
    max_len: int = 10,
  ) -> str:

  input_ids = english.encodeSentence(text)
  input_tensor = torch.LongTensor(input_ids).unsqueeze(1).to(device)

  with torch.no_grad():
    encoder_outputs, hidden = model1.encoder(input_tensor)

  trg_indexes = [irish.word2index["bof"]]

  for i in range(max_len):
    trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)

    with torch.no_grad():
      output, hidden = model1.decoder(trg_tensor, hidden, encoder_outputs)

    pred_token = torch.argmax(output).item()
    trg_indexes.append(pred_token)

    if pred_token == irish.word2index["eos"]:
      break

  return "".join(irish.decodeIds(trg_indexes))

bleu_score1 = []
for index,rows in test.iterrows():
  bleu_score1.append(blue_score(rows['targetString'],translate_sentence1(rows['sourceString'], model1, english, irish, device)))

np.mean(bleu_score1)

"""# Which model is the best for translation.

The encoder-decoder models have been proved to be efficient for translation both with and without attention. For translation jobs, the model with attention has proven to be more successful, particularly for lengthy and difficult texts.

In order to generate each word of the output, the attention method enables the decoder to concentrate on pertinent portions of the input. This feature is especially helpful when handling lengthy sentences with several dependencies. By doing this, the translation's accuracy and fluidity can be increased.
"""